{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaana's quest\n",
    "\n",
    "Noniin, testi tässä. Tulokset **eivät** kovin mairittelevia ole. Syytän osaksi Jupyteria, joka jostain syystä päätti lopettaa toimintansa tunnin jälkeen, jonka jälkeen menin muutaman tunnin sokkona kunnes sain softan heräämään.\n",
    "\n",
    "Malli on treenattu huikealla 8% tarkkuudella viimeisen tunnin sisällä, jona aikana lähes kaikki dokumentissa oleva sisältö on tehty.\n",
    "\n",
    "Ratkaisu on treenautettu vuoden 2018 asematiedoilla, eli parsittu datasta ainoastaan HKI-TRE reitillä olevien asemien `differenceInMinutes` -tietue, joka siis indikoi junan sen hetkisen aikataulun. Parempiakin ratkaisuja varmasti olisi, mutta (kiireessä) päädyin tähän. Optimointia ei ole suoritettu ollenkaan (Ja logistinen regressiomalli ei välttämättä myöskään se paras tähän ole...), esim. paremmalla / siivotummalla datasetillä, _gradient descent_ metodilla etc. tulokset olisivat varmasti parempia.\n",
    "\n",
    "Datan puolesta lisäisin siihen ainakin sääolosuhteet, koska ne varmasti ovat pääsyy aikataulujen muutoksiin.\n",
    "\n",
    "Kiitokset.\n",
    "\n",
    "-Ville R.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "# Where to stop to in the TimeTableRows\n",
    "TPE_SLICE = 90\n",
    "API_URL = 'https://rata.digitraffic.fi/api/v1/trains'\n",
    "START_DATE = date(2018, 1, 1)\n",
    "END_DATE = date(2018, 8, 22)\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "def reshape(df):\n",
    "    cols = df.stationShortCode.tolist()\n",
    "    row = df.differenceInMinutes.tolist()\n",
    "    new_df = pd.DataFrame([row], columns=cols)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def get_data(date, train = 45):\n",
    "    \"\"\"\n",
    "    Get data from API\n",
    "    \"\"\"\n",
    "    import json\n",
    "    \n",
    "    # If the file already exists => do not add headers\n",
    "    add_headers = False\n",
    "    \n",
    "    try:\n",
    "        file = open('data.csv', 'r')\n",
    "    except IOError:\n",
    "        file = open('data.csv', 'w')\n",
    "        add_headers = True\n",
    "    file.close()\n",
    "    \n",
    "    try:\n",
    "        url = '{0}/{1}/{2}'.format(API_URL, date, train)\n",
    "        print('getting data for date {}'.format(date))\n",
    "        r = requests.get(url, headers={'Cache-Control': 'no-cache'})\n",
    "        data = r.json()\n",
    "        ttRows = json.dumps(data[0].get('timeTableRows')[0:TPE_SLICE])\n",
    "        df = pd.read_json(ttRows)\n",
    "\n",
    "        shaped = reshape(df)\n",
    "\n",
    "        return shaped.to_csv('data.csv', mode='a', header=add_headers)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Comment for getting new data\n",
    "#for d in daterange(START_DATE, END_DATE):\n",
    "#    get_data(d.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0847457627118644"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "#df.shape\n",
    "#df.describe()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('TPE',axis=1),df.TPE, random_state=42)\n",
    "\n",
    "# Lez training-montage =>\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mdl.pkl', 'wb') as fid:\n",
    "    pickle.dump(model, fid,2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
